[2023-12-27 01:57:01,906] {processor.py:153} INFO - Started process (PID=37) to work on /opt/airflow/dags/scripts.py
[2023-12-27 01:57:01,906] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 01:57:01,907] {logging_mixin.py:115} INFO - [2023-12-27 01:57:01,907] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 01:57:01,911] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 01:57:01,972] {logging_mixin.py:115} INFO - [2023-12-27 01:57:01,972] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 01:57:01,979] {logging_mixin.py:115} INFO - [2023-12-27 01:57:01,979] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 01:57:01,990] {logging_mixin.py:115} INFO - [2023-12-27 01:57:01,990] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 01:57:01,994] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 57, 1, 990566, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 01:57:32,063] {processor.py:153} INFO - Started process (PID=65) to work on /opt/airflow/dags/scripts.py
[2023-12-27 01:57:32,063] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 01:57:32,064] {logging_mixin.py:115} INFO - [2023-12-27 01:57:32,064] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 01:57:32,070] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 01:57:32,108] {logging_mixin.py:115} INFO - [2023-12-27 01:57:32,108] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 01:57:32,112] {logging_mixin.py:115} INFO - [2023-12-27 01:57:32,112] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 01:57:32,118] {logging_mixin.py:115} INFO - [2023-12-27 01:57:32,118] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 01:57:32,122] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (626 characters truncated) ...  57, 32, 118664, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 01:58:02,180] {processor.py:153} INFO - Started process (PID=93) to work on /opt/airflow/dags/scripts.py
[2023-12-27 01:58:02,186] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 01:58:02,186] {logging_mixin.py:115} INFO - [2023-12-27 01:58:02,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 01:58:02,192] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 01:58:02,229] {logging_mixin.py:115} INFO - [2023-12-27 01:58:02,229] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 01:58:02,234] {logging_mixin.py:115} INFO - [2023-12-27 01:58:02,234] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 01:58:02,242] {logging_mixin.py:115} INFO - [2023-12-27 01:58:02,241] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 01:58:02,245] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 58, 2, 241735, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 01:58:32,321] {processor.py:153} INFO - Started process (PID=112) to work on /opt/airflow/dags/scripts.py
[2023-12-27 01:58:32,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 01:58:32,329] {logging_mixin.py:115} INFO - [2023-12-27 01:58:32,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 01:58:32,342] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 01:58:32,378] {logging_mixin.py:115} INFO - [2023-12-27 01:58:32,378] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 01:58:32,382] {logging_mixin.py:115} INFO - [2023-12-27 01:58:32,382] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 01:58:32,388] {logging_mixin.py:115} INFO - [2023-12-27 01:58:32,388] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 01:58:32,391] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (626 characters truncated) ...  58, 32, 387939, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 01:59:02,460] {processor.py:153} INFO - Started process (PID=140) to work on /opt/airflow/dags/scripts.py
[2023-12-27 01:59:02,466] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 01:59:02,467] {logging_mixin.py:115} INFO - [2023-12-27 01:59:02,467] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 01:59:02,480] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 01:59:02,520] {logging_mixin.py:115} INFO - [2023-12-27 01:59:02,520] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 01:59:02,524] {logging_mixin.py:115} INFO - [2023-12-27 01:59:02,524] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 01:59:02,530] {logging_mixin.py:115} INFO - [2023-12-27 01:59:02,530] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 01:59:02,533] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 59, 2, 529943, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 01:59:32,602] {processor.py:153} INFO - Started process (PID=168) to work on /opt/airflow/dags/scripts.py
[2023-12-27 01:59:32,608] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 01:59:32,609] {logging_mixin.py:115} INFO - [2023-12-27 01:59:32,609] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 01:59:32,623] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 01:59:32,660] {logging_mixin.py:115} INFO - [2023-12-27 01:59:32,660] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 01:59:32,664] {logging_mixin.py:115} INFO - [2023-12-27 01:59:32,664] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 01:59:32,670] {logging_mixin.py:115} INFO - [2023-12-27 01:59:32,670] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 01:59:32,673] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (626 characters truncated) ...  59, 32, 670305, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:00:02,743] {processor.py:153} INFO - Started process (PID=196) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:00:02,751] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:00:02,752] {logging_mixin.py:115} INFO - [2023-12-27 02:00:02,752] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:00:02,766] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:00:02,806] {logging_mixin.py:115} INFO - [2023-12-27 02:00:02,806] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:00:02,810] {logging_mixin.py:115} INFO - [2023-12-27 02:00:02,810] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:00:02,816] {logging_mixin.py:115} INFO - [2023-12-27 02:00:02,815] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:00:02,818] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 0, 2, 815797, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:00:32,886] {processor.py:153} INFO - Started process (PID=221) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:00:32,887] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:00:32,888] {logging_mixin.py:115} INFO - [2023-12-27 02:00:32,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:00:32,896] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:00:32,947] {logging_mixin.py:115} INFO - [2023-12-27 02:00:32,947] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:00:32,951] {logging_mixin.py:115} INFO - [2023-12-27 02:00:32,951] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:00:32,958] {logging_mixin.py:115} INFO - [2023-12-27 02:00:32,958] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:00:32,961] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 0, 32, 958190, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:01:03,028] {processor.py:153} INFO - Started process (PID=242) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:01:03,029] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:01:03,030] {logging_mixin.py:115} INFO - [2023-12-27 02:01:03,030] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:01:03,040] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:01:03,077] {logging_mixin.py:115} INFO - [2023-12-27 02:01:03,077] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:01:03,082] {logging_mixin.py:115} INFO - [2023-12-27 02:01:03,082] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:01:03,088] {logging_mixin.py:115} INFO - [2023-12-27 02:01:03,088] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:01:03,091] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (623 characters truncated) ...  2, 1, 3, 88205, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:01:33,156] {processor.py:153} INFO - Started process (PID=270) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:01:33,163] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:01:33,163] {logging_mixin.py:115} INFO - [2023-12-27 02:01:33,163] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:01:33,171] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:01:33,207] {logging_mixin.py:115} INFO - [2023-12-27 02:01:33,207] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:01:33,211] {logging_mixin.py:115} INFO - [2023-12-27 02:01:33,211] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:01:33,217] {logging_mixin.py:115} INFO - [2023-12-27 02:01:33,217] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:01:33,220] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 1, 33, 217516, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:02:03,279] {processor.py:153} INFO - Started process (PID=298) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:02:03,286] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:02:03,286] {logging_mixin.py:115} INFO - [2023-12-27 02:02:03,286] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:02:03,298] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:02:03,334] {logging_mixin.py:115} INFO - [2023-12-27 02:02:03,334] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:02:03,338] {logging_mixin.py:115} INFO - [2023-12-27 02:02:03,338] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:02:03,344] {logging_mixin.py:115} INFO - [2023-12-27 02:02:03,344] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:02:03,347] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 2, 3, 344041, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:02:33,407] {processor.py:153} INFO - Started process (PID=326) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:02:33,408] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:02:33,408] {logging_mixin.py:115} INFO - [2023-12-27 02:02:33,408] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:02:33,414] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:02:33,449] {logging_mixin.py:115} INFO - [2023-12-27 02:02:33,449] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:02:33,453] {logging_mixin.py:115} INFO - [2023-12-27 02:02:33,453] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:02:33,459] {logging_mixin.py:115} INFO - [2023-12-27 02:02:33,459] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:02:33,462] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 2, 33, 459580, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:03:03,478] {processor.py:153} INFO - Started process (PID=345) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:03:03,478] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:03:03,478] {logging_mixin.py:115} INFO - [2023-12-27 02:03:03,478] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:03:03,484] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:03:03,524] {logging_mixin.py:115} INFO - [2023-12-27 02:03:03,524] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:03:03,529] {logging_mixin.py:115} INFO - [2023-12-27 02:03:03,528] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:03:03,536] {logging_mixin.py:115} INFO - [2023-12-27 02:03:03,536] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:03:03,540] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 3, 3, 536644, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:03:33,587] {processor.py:153} INFO - Started process (PID=373) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:03:33,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:03:33,594] {logging_mixin.py:115} INFO - [2023-12-27 02:03:33,594] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:03:33,599] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:03:33,636] {logging_mixin.py:115} INFO - [2023-12-27 02:03:33,635] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:03:33,640] {logging_mixin.py:115} INFO - [2023-12-27 02:03:33,640] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:03:33,646] {logging_mixin.py:115} INFO - [2023-12-27 02:03:33,646] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:03:33,649] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 3, 33, 646293, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:04:03,671] {processor.py:153} INFO - Started process (PID=401) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:04:03,677] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:04:03,678] {logging_mixin.py:115} INFO - [2023-12-27 02:04:03,678] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:04:03,691] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:04:03,734] {logging_mixin.py:115} INFO - [2023-12-27 02:04:03,734] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:04:03,739] {logging_mixin.py:115} INFO - [2023-12-27 02:04:03,739] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:04:03,745] {logging_mixin.py:115} INFO - [2023-12-27 02:04:03,745] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:04:03,748] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 4, 3, 744885, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:04:33,783] {processor.py:153} INFO - Started process (PID=429) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:04:33,790] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:04:33,790] {logging_mixin.py:115} INFO - [2023-12-27 02:04:33,790] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:04:33,802] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:04:33,839] {logging_mixin.py:115} INFO - [2023-12-27 02:04:33,839] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:04:33,844] {logging_mixin.py:115} INFO - [2023-12-27 02:04:33,843] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:04:33,850] {logging_mixin.py:115} INFO - [2023-12-27 02:04:33,850] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:04:33,853] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 4, 33, 850013, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:05:03,878] {processor.py:153} INFO - Started process (PID=448) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:05:03,884] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:05:03,885] {logging_mixin.py:115} INFO - [2023-12-27 02:05:03,885] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:05:03,891] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:05:03,927] {logging_mixin.py:115} INFO - [2023-12-27 02:05:03,927] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:05:03,931] {logging_mixin.py:115} INFO - [2023-12-27 02:05:03,931] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:05:03,938] {logging_mixin.py:115} INFO - [2023-12-27 02:05:03,938] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:05:03,941] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 5, 3, 937921, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:05:33,987] {processor.py:153} INFO - Started process (PID=476) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:05:33,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:05:33,994] {logging_mixin.py:115} INFO - [2023-12-27 02:05:33,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:05:34,004] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:05:34,039] {logging_mixin.py:115} INFO - [2023-12-27 02:05:34,039] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:05:34,043] {logging_mixin.py:115} INFO - [2023-12-27 02:05:34,043] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:05:34,049] {logging_mixin.py:115} INFO - [2023-12-27 02:05:34,049] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:05:34,052] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 5, 34, 49257, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:06:04,082] {processor.py:153} INFO - Started process (PID=504) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:06:04,082] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:06:04,082] {logging_mixin.py:115} INFO - [2023-12-27 02:06:04,082] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:06:04,088] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:06:04,123] {logging_mixin.py:115} INFO - [2023-12-27 02:06:04,122] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:06:04,126] {logging_mixin.py:115} INFO - [2023-12-27 02:06:04,126] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:06:04,132] {logging_mixin.py:115} INFO - [2023-12-27 02:06:04,132] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:06:04,135] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 6, 4, 132429, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:06:34,186] {processor.py:153} INFO - Started process (PID=532) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:06:34,192] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:06:34,193] {logging_mixin.py:115} INFO - [2023-12-27 02:06:34,193] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:06:34,207] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:06:34,244] {logging_mixin.py:115} INFO - [2023-12-27 02:06:34,244] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:06:34,248] {logging_mixin.py:115} INFO - [2023-12-27 02:06:34,248] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:06:34,253] {logging_mixin.py:115} INFO - [2023-12-27 02:06:34,253] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:06:34,256] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 6, 34, 253666, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:07:04,279] {processor.py:153} INFO - Started process (PID=558) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:07:04,285] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:07:04,285] {logging_mixin.py:115} INFO - [2023-12-27 02:07:04,285] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:07:04,292] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:07:04,332] {logging_mixin.py:115} INFO - [2023-12-27 02:07:04,332] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:07:04,337] {logging_mixin.py:115} INFO - [2023-12-27 02:07:04,337] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:07:04,344] {logging_mixin.py:115} INFO - [2023-12-27 02:07:04,344] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:07:04,348] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 7, 4, 344513, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:07:34,391] {processor.py:153} INFO - Started process (PID=579) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:07:34,392] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:07:34,392] {logging_mixin.py:115} INFO - [2023-12-27 02:07:34,392] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:07:34,399] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:07:34,441] {logging_mixin.py:115} INFO - [2023-12-27 02:07:34,441] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:07:34,445] {logging_mixin.py:115} INFO - [2023-12-27 02:07:34,445] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:07:34,452] {logging_mixin.py:115} INFO - [2023-12-27 02:07:34,452] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:07:34,456] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 7, 34, 452528, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:08:04,491] {processor.py:153} INFO - Started process (PID=607) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:08:04,494] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:08:04,495] {logging_mixin.py:115} INFO - [2023-12-27 02:08:04,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:08:04,506] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:08:04,543] {logging_mixin.py:115} INFO - [2023-12-27 02:08:04,543] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:08:04,547] {logging_mixin.py:115} INFO - [2023-12-27 02:08:04,547] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:08:04,553] {logging_mixin.py:115} INFO - [2023-12-27 02:08:04,553] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:08:04,557] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 8, 4, 553708, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:08:34,592] {processor.py:153} INFO - Started process (PID=635) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:08:34,593] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:08:34,593] {logging_mixin.py:115} INFO - [2023-12-27 02:08:34,593] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:08:34,605] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:08:34,643] {logging_mixin.py:115} INFO - [2023-12-27 02:08:34,643] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:08:34,647] {logging_mixin.py:115} INFO - [2023-12-27 02:08:34,647] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:08:34,653] {logging_mixin.py:115} INFO - [2023-12-27 02:08:34,653] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:08:34,657] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 8, 34, 653625, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:09:04,692] {processor.py:153} INFO - Started process (PID=663) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:09:04,692] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:09:04,693] {logging_mixin.py:115} INFO - [2023-12-27 02:09:04,693] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:09:04,698] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:09:04,736] {logging_mixin.py:115} INFO - [2023-12-27 02:09:04,736] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:09:04,740] {logging_mixin.py:115} INFO - [2023-12-27 02:09:04,740] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:09:04,746] {logging_mixin.py:115} INFO - [2023-12-27 02:09:04,746] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:09:04,749] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (624 characters truncated) ... 2, 9, 4, 746172, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:09:34,777] {processor.py:153} INFO - Started process (PID=682) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:09:34,779] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:09:34,780] {logging_mixin.py:115} INFO - [2023-12-27 02:09:34,780] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:09:34,785] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:09:34,820] {logging_mixin.py:115} INFO - [2023-12-27 02:09:34,820] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:09:34,824] {logging_mixin.py:115} INFO - [2023-12-27 02:09:34,824] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:09:34,830] {logging_mixin.py:115} INFO - [2023-12-27 02:09:34,830] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:09:34,833] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 9, 34, 829952, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:10:04,886] {processor.py:153} INFO - Started process (PID=711) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:10:04,886] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:10:04,887] {logging_mixin.py:115} INFO - [2023-12-27 02:10:04,887] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:10:04,892] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:10:04,929] {logging_mixin.py:115} INFO - [2023-12-27 02:10:04,929] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:10:04,933] {logging_mixin.py:115} INFO - [2023-12-27 02:10:04,933] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:10:04,939] {logging_mixin.py:115} INFO - [2023-12-27 02:10:04,939] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:10:04,942] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 10, 4, 938952, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:10:34,967] {processor.py:153} INFO - Started process (PID=739) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:10:34,967] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:10:34,967] {logging_mixin.py:115} INFO - [2023-12-27 02:10:34,967] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:10:34,974] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:10:35,021] {logging_mixin.py:115} INFO - [2023-12-27 02:10:35,021] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:10:35,027] {logging_mixin.py:115} INFO - [2023-12-27 02:10:35,027] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:10:35,035] {logging_mixin.py:115} INFO - [2023-12-27 02:10:35,035] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:10:35,039] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 10, 35, 35467, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
[2023-12-27 02:11:05,077] {processor.py:153} INFO - Started process (PID=767) to work on /opt/airflow/dags/scripts.py
[2023-12-27 02:11:05,083] {processor.py:641} INFO - Processing file /opt/airflow/dags/scripts.py for tasks to queue
[2023-12-27 02:11:05,084] {logging_mixin.py:115} INFO - [2023-12-27 02:11:05,084] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/scripts.py
[2023-12-27 02:11:05,097] {processor.py:651} INFO - DAG(s) dict_keys(['import_dag']) retrieved from /opt/airflow/dags/scripts.py
[2023-12-27 02:11:05,133] {logging_mixin.py:115} INFO - [2023-12-27 02:11:05,133] {dag.py:2371} INFO - Sync 1 DAGs
[2023-12-27 02:11:05,137] {logging_mixin.py:115} INFO - [2023-12-27 02:11:05,137] {dag.py:2390} INFO - Creating ORM DAG for import_dag
[2023-12-27 02:11:05,143] {logging_mixin.py:115} INFO - [2023-12-27 02:11:05,143] {dag.py:2919} INFO - Setting next_dagrun for import_dag to 2023-12-26T00:00:00+00:00, run_after=2023-12-26T00:01:00+00:00
[2023-12-27 02:11:05,146] {processor.py:164} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
KeyError: <class 'pendulum.duration.Duration'>

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 158, in _run_file_processor
    callback_requests=callback_requests,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 660, in process_file
    dagbag.sync_to_db()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 71, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 615, in sync_to_db
    for attempt in run_with_db_retries(logger=self.log):
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 382, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.7/site-packages/tenacity/__init__.py", line 349, in iter
    return fut.result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 428, in result
    return self.__get_result()
  File "/usr/local/lib/python3.7/concurrent/futures/_base.py", line 384, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 629, in sync_to_db
    DAG.bulk_write_to_db(self.dags.values(), session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2466, in bulk_write_to_db
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3255, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3395, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 72, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 3355, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 453, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 630, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 247, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1095, in _emit_insert_statements
    statement, multiparams, execution_options=execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1520, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 314, in _execute_on_connection
    self, multiparams, params, execution_options
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1399, in _execute_clauseelement
    cache_hit=cache_hit,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1615, in _execute_context
    e, util.text_type(statement), parameters, None, None
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1930, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1609, in _execute_context
    dialect, self, conn, execution_options, *args, **kw
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in _init_compiled
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 1074, in <dictcomp>
    for key in compiled_params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/type_api.py", line 1308, in process
    return process_param(value, dialect)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/sqlalchemy.py", line 169, in process_bind_param
    attrs = {key: getattr(value, key) for key in self.attr_keys[type(value)]}
sqlalchemy.exc.StatementError: (builtins.KeyError) <class 'pendulum.duration.Duration'>
[SQL: INSERT INTO dag (dag_id, root_dag_id, is_paused, is_subdag, is_active, last_parsed_time, last_pickled, last_expired, scheduler_lock, pickle_id, fileloc, owners, description, default_view, schedule_interval, timetable_description, max_active_tasks, max_active_runs, has_task_concurrency_limits, has_import_errors, next_dagrun, next_dagrun_data_interval_start, next_dagrun_data_interval_end, next_dagrun_create_after) VALUES (%(dag_id)s, %(root_dag_id)s, %(is_paused)s, %(is_subdag)s, %(is_active)s, %(last_parsed_time)s, %(last_pickled)s, %(last_expired)s, %(scheduler_lock)s, %(pickle_id)s, %(fileloc)s, %(owners)s, %(description)s, %(default_view)s, %(schedule_interval)s, %(timetable_description)s, %(max_active_tasks)s, %(max_active_runs)s, %(has_task_concurrency_limits)s, %(has_import_errors)s, %(next_dagrun)s, %(next_dagrun_data_interval_start)s, %(next_dagrun_data_interval_end)s, %(next_dagrun_create_after)s)]
[parameters: [{'next_dagrun_create_after': DateTime(2023, 12, 26, 0, 1, 0, tzinfo=Timezone('UTC')), 'timetable_description': '', 'dag_id': 'import_dag', 'descripti ... (625 characters truncated) ... , 11, 5, 143673, tzinfo=Timezone('UTC')), 'last_pickled': None, 'scheduler_lock': None, 'last_expired': None, 'pickle_id': None, 'root_dag_id': None}]]
